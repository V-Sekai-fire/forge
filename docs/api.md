# Forge API Reference

This document provides comprehensive technical documentation for the Zenoh-powered distributed AI platform Forge.

## Platform Components

### zimage (Python AI Service)

Location: `zimage/`
Technology: Python + Hugging Face Diffusers + Zenoh

**Service Interface:**
- **Transport**: FlatBuffers over Zenoh native protocol
- **Zenoh Key**: `forge/inference/zimage`
- **Data Format**: Binary FlatBuffers serialization

**Local Development:**
```python
# Start service
cd zimage && uv run python inference_service.py

# Service auto-registers with Zenoh router
# Uses flatbuffers for binary protocol communication
```

**Zenoh Integration:**
- **Liveliness Token**: `forge/services/zimage` (auto-announced)
- **Query Key**: `forge/inference/zimage`
- **Protocol**: FlatBuffers for efficient binary serialization

### zimage-client (Elixir CLI Tools)

Location: `zimage-client/`
Technology: Elixir with Zenoh connectivity

**CLI Interface:**
```bash
cd zimage-client
./zimage_client "generate this" --width 1024 --guidance-scale 0.5
./zimage_client --dashboard  # Real-time monitoring
./zimage_client --router     # Start zenohd
```

**Commands:**
- **generate**: Send image generation request via Zenoh
- **batch**: Generate multiple images
- **dashboard**: Live service monitoring
- **router**: Manage zenohd process

### zenoh-router (Router Management)

Location: `zenoh-router/`
Technology: Elixir process management + zenohd

**CLI Interface:**
```bash
cd zenoh-router
./zenoh_router start                 # Launch daemon
./zenoh_router status               # Health check
./zenoh_router stop                 # Graceful shutdown
./zenoh_router logs                 # View daemon output
```

**Zenohd Configuration:**
- TCP listener: `:7447`
- WebSocket: Enabled for browser connections
- REST API: `http://localhost:7447/@config`

## API Access

Forge uses **FlatBuffers over Zenoh native protocol** for high-performance distributed communication and computation.

### Zenoh Native Protocol

The primary interface uses FlatBuffers binary serialization over Zenoh's peer-to-peer networking:

#### Image Generation
```bash
# Direct FlatBuffers/Zenoh communication
./zimage_client "sunset over mountains" --width 1024 --height 1024 --guidance-scale 0.5
```

**CLI Available on all CLI implementations:**
- ✅ zimage-client (Elixir with Zenoh client)
- ✅ Custom Zenoh clients (Python, C++, Rust, etc.)

#### Batch Processing
```bash
# Generate multiple images
./zimage_client --batch "cat" "dog" "bird" --width 512
```

#### Service Status & Monitoring
```bash
# View real-time service dashboard
./zimage_client --dashboard

# Get individual AI service status
./zimage_client --status
```

### FlatBuffers Protocol

Forge uses FlatBuffers binary serialization for efficient data transfer:

**Schema Definitions:** See `zimage/flatbuffers/inference_request.fbs` and `zimage/flatbuffers/inference_response.fbs`

**Request Structure (FlatBuffers):**
```flatbuffers
// Binary serialized request containing:
prompt: string          // Required image description
width: int32 = 1024     // Image width
height: int32 = 1024    // Image height
num_steps: int32 = 4    // Inference steps
guidance_scale: double = 0.5  // Control strength
seed: int32 = 0         // Random seed (optional)
output_format: string = "png"  // Output format
```

**Response Structure (FlatBuffers):**
```flatbuffers
// Binary serialized response containing:
status: string          // "success" or "error"
result: string          // Image path or error message
metadata: vector<string>  // Key-value metadata pairs
image_data: vector<ubyte>  // Optional embedded image bytes
```

## Error Codes

### Zenoh Network Errors
- `E0001`: Router not found
- `E0002`: Service unreachable
- `E0003`: Network timeout

### AI Service Errors
- `A0001`: Invalid prompt
- `A0002`: Image generation failed
- `A0003`: GPU memory exceeded

### Configuration Errors
- `C0001`: Zenohd not installed
- `C0002`: Dependencies missing

## Configuration

### Environment Variables
```bash
# Zenoh configuration
ZENOH_CONFIG=config.json

# AI model paths
FORGE_MODEL_PATH=./pretrained_weights

# Service ports
ROUTER_PORT=7447
```

### Default Configurations
```yaml
# zenohd.yml - Basic Zenoh router configuration
listen:
  - tcp/[::]:7447

# Optional: Add websockets for browser connectivity
ws:
  enabled: true
```

## Performance Metrics

### AI Generation
- **Model**: Z-Image-Turbo (optimized diffusers)
- **GPU Acceleration**: torch.compile + CUDA
- **Memory**: ~2-4GB VRAM for 1024x1024 images
- **Speed**: ~2-5 seconds per image

### Network Transport
- **Protocol**: Zenoh native with FlatBuffers
- **Serialization**: Binary FlatBuffers (zero-copy)
- **Compression**: Built-in Zenoh optimization
- **Latency**: Sub-millisecond local, <10ms LAN

## Testing

### Unit Tests
```bash
# Python
cd zimage && uv run pytest

# Elixir
cd zimage-client && mix test
cd zenoh-router && mix test
```

### Integration Tests
```bash
# Automated system test
./test_e2e.sh

# Manual component testing
zenohd &
./zenoh-router/zenoh_router status
./zimage_client --dashboard
```

## Troubleshooting

### Common Issues

**Zenohd not found:**
```
Install with: cargo install zenohd
Or download pre-built binaries from zenoh.io/download
```

**Services not connecting:**
```
Ensure zenohd is running: ./zenoh-router/zenoh_router status
Check firewall: ports 7447, TCP
```

**AI generation slow/export:**
```
Verify CUDA: python -c "import torch; print(torch.cuda.is_available())"
Check VRAM: ~4GB free needed
Update drivers if issues
```

### Logs and Debugging

**Service Logs:**
- Zenoh router: `./zenoh-router/zenoh_router logs`
- AI service: Run in foreground for stdout

**Zenoh Health:**
```bash
curl http://localhost:7447/@config/status
```

**Network Debugging:**
```bash
zenohd --debug  # Verbose networking
